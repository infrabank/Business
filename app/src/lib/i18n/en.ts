export const en = {
  nav: {
    features: 'Features',
    compare: 'Compare',
    pricing: 'Pricing',
    faq: 'FAQ',
    login: 'Log In',
    getStarted: 'Get Started Free',
  },
  hero: {
    badge: 'Free until we save you money — then just 20% of savings',
    titlePrefix: 'Cut LLM costs by ',
    titleHighlight: '40%+',
    titleSuffix: '',
    titleSub: 'with a single line of code',
    description: 'Point your API endpoint to our proxy. We auto-cache duplicate requests and AI-route simple queries to cheaper models. ',
    descriptionBold: 'Same results, less than half the cost.',
    ctaPrimary: 'Start Saving Free',
    ctaSecondary: 'View Pricing',
    trust1: 'No credit card required',
    trust2: '1-line integration',
    trust3: 'OpenAI, Anthropic, Google supported',
  },
  mockup: {
    urlBar: 'app.llmcost.io/proxy/savings',
    withoutLcm: 'Without LCM',
    originalAmount: 'What you would have paid',
    savings: 'Savings',
    reduction: '41.4% less',
    withLcm: 'With LCM',
    actualAmount: 'Actually paid',
    savingsBreakdown: 'Savings breakdown',
    responseCaching: 'Response caching',
    smartRouting: 'Smart model routing',
    recentOptimizations: 'Recent optimizations',
    routingDetail: '512 simple Q&A and greeting requests',
    cacheHitRate: 'Cache hit rate',
    cacheDetail: '1,847 duplicate calls eliminated',
    liveRequestLog: 'Live request log',
  },
  codeSnippet: {
    title: '1-line change, instant savings',
    subtitle: 'Keep using your existing OpenAI/Anthropic/Google SDK. Just change the base_url and the proxy optimizes automatically.',
    highlight: 'Change only these two lines',
    badge1: 'OpenAI SDK compatible',
    badge2: 'Anthropic SDK compatible',
    badge3: 'Google AI SDK compatible',
  },
  compare: {
    title: 'Why LLM Cost Manager over the competition?',
    subtitle: 'Transparent cost savings with zero infrastructure management. Results speak for themselves.',
    headers: {
      feature: 'Feature',
      lcm: 'LLM Cost Manager',
      litellm: 'LiteLLM',
      helicone: 'Helicone',
      portkey: 'Portkey',
    },
    rows: {
      setup: 'Setup complexity',
      setupLcm: '1-line change',
      setupOther1: 'Server deployment',
      setupOther2: 'SDK integration',
      setupOther3: 'SDK integration',
      pricing: 'Pricing model',
      pricingLcm: '20% of savings',
      pricingOther1: 'Open source / Enterprise',
      pricingOther2: 'Per-request pricing',
      pricingOther3: 'Per-request pricing',
      caching: 'Semantic caching',
      cachingLcm: '3-level caching',
      routing: 'Smart routing',
      routingLcm: 'AI intent-based',
      dashboard: 'Cost dashboard',
      guardrails: 'PII guardrails',
      fallback: 'Auto fallback',
      budget: 'Budget management',
    },
    highlights: {
      title: 'Key differentiators',
      item1Title: 'Performance-based pricing',
      item1Desc: 'Pay only for what we save you. No savings, no cost.',
      item2Title: 'Zero infrastructure',
      item2Desc: 'No server deployment, Docker, or management needed. Just change one URL.',
      item3Title: '3-level semantic caching',
      item3Desc: 'Exact match → normalized → Jaccard similarity matching for maximum hit rate.',
    },
  },
  costSavings: {
    title: 'Cost Savings Simulator',
    subtitle: 'Enter your monthly LLM spend and see projected savings',
    inputLabel: 'Monthly LLM cost ($)',
    currentCost: 'Current monthly cost',
    withLcm: 'With LCM',
    monthlySavings: 'Monthly savings',
    commission: 'LCM fee (20%)',
    netSavings: 'Net savings',
    yearlyProjection: 'Projected annual savings',
    cacheSavings: 'Caching savings',
    routingSavings: 'Routing savings',
    ctaText: 'Start saving now',
  },
  howItWorks: {
    title: 'How it works',
    subtitle: 'Start saving in 3 simple steps',
  },
  stats: {
    title: 'Results by the numbers',
  },
  testimonials: {
    title: 'What our customers say',
    subtitle: 'Teams already cutting their LLM costs',
  },
  faqSection: {
    title: 'Frequently asked questions',
    subtitle: 'Everything you need to know',
  },
  cta: {
    badge: 'Average setup time: 2 minutes',
    titlePrefix: 'Still overpaying 40% on',
    titleHighlight: 'your monthly LLM bill',
    titleSuffix: '?',
    description: 'Every moment you wait is money wasted on duplicate API calls and expensive models. Change one URL. Savings start instantly.',
    ctaPrimary: 'Start Saving Free',
    ctaSecondary: 'View Pricing',
    trust1: 'No credit card required',
    trust2: 'Free plan available',
    trust3: 'No savings, no cost',
  },
  login: {
    title: 'Log in to your account',
    emailLabel: 'Email',
    emailPlaceholder: 'you@company.com',
    passwordLabel: 'Password',
    passwordPlaceholder: 'Enter password',
    submit: 'Log In',
    submitting: 'Logging in...',
    noAccount: "Don't have an account?",
    signupLink: 'Sign up free',
    emailError: 'Please enter a valid email address',
    passwordError: 'Password must be at least 8 characters',
    showPassword: 'Show password',
    hidePassword: 'Hide password',
  },
  signup: {
    title: 'Create a free account',
    nameLabel: 'Name',
    namePlaceholder: 'Enter your name',
    emailLabel: 'Email',
    emailPlaceholder: 'you@company.com',
    passwordLabel: 'Password',
    passwordPlaceholder: 'Min 8 characters',
    submit: 'Create Account',
    submitting: 'Creating account...',
    freePlanNote: 'Free plan includes 1 provider, 7-day history, and basic dashboard.',
    hasAccount: 'Already have an account?',
    loginLink: 'Log in',
    nameError: 'Please enter your name',
    emailError: 'Please enter a valid email address',
    passwordError: 'Password must be at least 8 characters',
    showPassword: 'Show password',
    hidePassword: 'Hide password',
  },
  logoBanner: {
    title: 'Trusted by innovative teams',
  },
  landingData: {
    features: [
      {
        title: 'Automatic cost reduction',
        description: 'The proxy auto-caches identical requests and uses AI to route simple queries to cheaper models. Most teams see 30-60% savings from day one.',
      },
      {
        title: 'Real-time per-request tracking',
        description: 'See the exact cost of every API call in real time. Know which requests are expensive and which are optimized at a glance.',
      },
      {
        title: 'Before & after dashboard',
        description: 'Compare what you would have paid without LCM vs what you actually paid. Clear ROI in dollar amounts, every single day.',
      },
      {
        title: 'Smart response caching',
        description: 'Identical prompts get instant cached responses without calling the API again. Zero latency, zero cost — applied to every request automatically.',
      },
      {
        title: 'Intelligent model routing',
        description: 'AI-powered intent classifier understands each request. Coding and analysis use premium models. Simple Q&A and greetings auto-route to cheaper alternatives — up to 94% savings per request.',
      },
      {
        title: 'Budget guardrails',
        description: 'Set strict spending limits per API key. When the budget hits the cap, requests are blocked — no more surprise bills at month-end.',
      },
    ],
    steps: [
      {
        title: 'Change your API endpoint',
        description: 'Replace api.openai.com with the proxy URL. One line change — your existing code works exactly the same.',
      },
      {
        title: 'Every request is optimized',
        description: 'AI intent classification, response caching, budget enforcement — all automatic. Coding goes to GPT-4o, simple Q&A routes to GPT-4o-mini. No extra code needed.',
      },
      {
        title: 'Watch your bill shrink',
        description: 'See real-time savings on the dashboard. Most teams cut 30-60% in the first week. The service pays for itself.',
      },
    ],
    stats: [
      { value: '42%', label: 'Avg. cost reduction' },
      { value: '$0', label: 'Cached response cost' },
      { value: '1 line', label: 'Code change to start' },
      { value: '<2 min', label: 'Setup time' },
    ],
    testimonials: [
      {
        quote: 'Just changed one URL and our OpenAI bill dropped from $8,200 to $3,400 in the first month. Response caching alone saved $2,800 on duplicate embedding calls.',
        name: 'James Kim',
        role: 'CTO',
        company: 'Plio AI',
      },
      {
        quote: "We were making bulk GPT-4o calls for simple classification tasks. LCM auto-routed to GPT-4o-mini and we couldn't tell the difference in quality. 85% cost reduction on those calls.",
        name: 'Rachel Torres',
        role: 'ML Engineer',
        company: 'Stackline',
      },
      {
        quote: 'The before-and-after dashboard convinced our CFO. We could see exactly how much we were saving — $4,100 last month. Budget approved in 5 minutes.',
        name: 'David Park',
        role: 'VP of Engineering',
        company: 'Convexa',
      },
    ],
    faqItems: [
      {
        question: 'How does pricing work?',
        answer: "Pure commission model — no monthly fees. We take 20% of the savings from caching and smart routing. If there's no savings, there's no cost. You can see exact savings and commission in real time on your dashboard.",
      },
      {
        question: 'How much can I actually save?',
        answer: 'Depends on your usage patterns. Teams with repetitive prompts (embeddings, classification, templates) typically save 40-60% from caching alone. AI-powered intent routing adds another 20-30% — the classifier detects simple queries and auto-routes to cheaper models. Check your exact savings in real time on the dashboard.',
      },
      {
        question: 'Does routing to cheaper models affect quality?',
        answer: 'The AI intent classifier analyzes each request to understand what is being asked. Coding, analysis, creative writing, and reasoning always use your chosen premium model. Only simple questions, greetings, and translations route to cheaper alternatives — quality-critical work is never compromised.',
      },
      {
        question: 'How does the proxy work with my existing code?',
        answer: "Change the base URL in your API client from api.openai.com to the proxy URL and use an LCM proxy key instead of your real API key. That's it — one line change. Your real API key is encrypted and stored securely on our servers.",
      },
      {
        question: 'Are my API keys safe?',
        answer: "Real API keys are encrypted with AES-256-GCM before storage. You get a proxy key (lmc_xxx) to use instead. Even our team can't see your original keys. Proxy keys can be revoked instantly.",
      },
      {
        question: 'Which providers are supported?',
        answer: 'We support OpenAI, Anthropic (Claude), and Google AI (Gemini). All three get caching, smart routing, and real-time cost tracking through the proxy.',
      },
      {
        question: 'What happens when a budget limit is reached?',
        answer: 'When a proxy key hits its budget limit, subsequent requests return a 429 status code. Your application handles it like a normal rate limit. No surprise bills, ever.',
      },
    ],
  },
} as const
